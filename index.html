<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link href="./pages/style.css" rel="stylesheet">
</head>

<body>
    <div class="header">
        <h1>Development Environment Exam Project</h1>
    </div>

    <div class="names">
        <div>Brigitta-Roberta Rucz, Michell Aagaard Dranig, Hyun Ji Lee</div>
        <div>June 2, 2021</div>
    </div>

    <div class="toc">
        <div class="subheader1"> Table of Contents </div>
        <ol>
            <li><a href="#Introduction">Introduction</a></li>
            <li><a href="#Requirement">Requirement Specifications</a></li>
            <li><a href="#Containerization">Containerization</a></li>
            <li>
                <a href="#SoftwareQA">Software Quality Assurance</a>
                <ol>
                    <li><a href="#SoftwareQACodingStandard">Coding Standard</a></li>
                    <li><a href="#SoftwareQARelevancy">Relevancy of Tests</a></li>
                    <li><a href="#SoftwareQATesting">Testing</a></li>
                    <li><a href="#SoftwareQALinting">Linting</a></li>
                    <li><a href="#SoftwareQACICD">CI/CD</a></li>
                    <li><a href="#SoftwareQAGitLabPages">GitLab Pages</a></li>
                    <li><a href="#SoftwareQADocumentation">Documentation</a></li>
                </ol>
            </li>
            <li><a href="#VersionControl">Version Control System</a></li>
            <li><a href="#DatabaseSystem">Database System</a></li>
            <li><a href="#OperatingSystem">Operating System Components</a></li>
        </ol>
    </div>

    <div class="contents">
        <a id="Introduction"></a>
        <div class="subheader1"> Introduction </div>
        <div class="text">
            <div>
                We live in a world where online communication has never been more important - especially after the covid
                pandemic hit the world last year. The coding world has been using various platforms to communicate
                online and organize their teamwork for years, but most people still had the possibility to
                actually talk to their co-workers face to face about possible issues. Developing this project has shown
                us how important it is to know how to communicate online and all the tools we’ve used has really helped
                us develop a product that’s maintainable for everyone.
            </div>
            <div>
                During the course of this semester, we’ve covered ways to structure and manage our code easier when
                working in a team along with ensuring that our code lives up to best practice standards. For this exam
                we chose a previous project done by one of us and started improving the standard of the code and along
                the way also making it more maintainable. This report will explain all our choices, decisions and gives
                a clear overview of why we made the decisions we did and how it improved this project.
            </div>
        </div>

        <a id="Requirement"></a>
        <div class="subheader1">Requirement Specifications</div>
        <div class="text">
            <div>
                For larger projects there are standards for requirement specifications but for smaller projects it is
                way too much to abide by those standards but it’s still a tool we can benefit from. It’s a document
                where you write down all the requirements for the project from several perspectives and can be used as a
                great overview and structure for your project. For our case we’ve created a spreadsheet where we’ve
                written down the different sets of requirements based on three different sides: the business, users and
                system. All requirements have an ID that we can reference to throughout the spreadsheet to keep track of
                which requirements need what functionalities. We also have a column that states whether the requirement
                is functional or non-functional. When creating a website all functionalities are usually not included in
                the first release so therefore, we have a column for MoSCoW to state if the requirement is a must,
                should, could or won't and also a version number for each requirement based on that.
            </div>
            <div>
                In order to make sure that we covered everything we looked at the project from a business point of view
                first since they would normally be the ones who would give us, the developers, their wishes and needs
                for a project. Almost all business requirements are referenced in either user- or system requirements,
                or both, in order to actually meet the requirements of the business. One example is the business
                requirement with ID 2. This states the company wants to “Support tech event recommendations”. The
                company wants to be able to recommend events to users. Now from a user’s point of view we don’t want
                recommendations that are not based on our own interests so therefore the user requirement with ID 9
                states “Users can get personalized recommendations of events”. It’s important for the user to know that
                we give them something they might actually be interested in. We have a comment column so we can write
                down small notes or further explanations of how each requirement could be fulfilled. For this instance
                we wrote a little note to state that the personalized suggestions should be based on interests set on
                the users profile.
            </div>
            <img src="./pages/images/requirements1.png" alt="Requirement Specifications List" />
        </div>

        <a id="Containerization"></a>
        <div class="subheader1">Containerization</div>
        <div class="text">
            <div>
                Docker and its characteristic of process isolation brings with it a myriad of benefits compared to a VM
                environment. VMs run an OS on top of which all the other’s system processes need to run, which can be
                consuming when it comes to RAM and CPU. Containers, however, share only the host OS, providing OS
                virtualization which is known as containerization.
            </div>
            <div>
                In a business setting, containers improve the workflows through reduced human resources, hardware costs
                and provide enhanced security through a modular architecture, which allows adding or replacing any
                module without this interfering with the rest of the system. However, it is important to mention that
                there are also downsides that ought to be addressed in areas that include shared resources, as this can
                potentially lead to application interference or crashing, safety, as isolation is not guaranteed and
                security, as good practice suggests that no data should be stored inside them.
            </div>
            <div>
                We have practiced containerization through a NodeJS based application connected to an SQL database,
                specifically MariaDB. As a workflow, the start was carved by creating a Dockerfile to allow spinning up
                the application in a compact Linux distribution, Alpine, with Node 15.11.0 installed. Then instructions
                are being executed, out of which of high relevancy is “FROM” that is used to set the base image.
                Afterwards “CMD”, at the end of the file specifies the command to run within the container corresponding
                to the very same script used in package.json to run the application.
            </div>
            <div>
                In the terminal, the command “docker build -t node-app .” builds the image tagging it ( -t ) after which
                “docker run -d -p 3000:3000 node-app” creates the container with the specified image running it as a
                process ( -d ) binding the port 3000 of the container to the port 3000 of the host machine ( -p ). In
                this way, testing to see if the Dockerfile successfully fulfils its scope is executed.
            </div>
            <div>
                Further, we ought to proceed with pulling and running MariaDB and testing the connectivity between the
                application layer and the database layer in containers. This requires modifying the database
                configurations in the NodeJS files accordingly. When successful, NGINX is added to the mix which will
                act as a web server, a reverse proxy and a load balancer, all at once. To dig a bit deeper into the
                terms, the web server will retrieve the HTTP requests forwarding them to the application by acting as a
                reverse proxy, routing these further by never revealing the original IP address to the client, enhancing
                security. Simultaneously, the property of load balancing protects the servers from crashing due to
                increased traffic.
            </div>
            <div>
                When it comes to the implementation, this is done via making use of another Dockerfile through which
                again, the base image is set following the “COPY” instruction to provide initial necessary
                configurations. Related to default.conf file, here we have to discuss about the core contexts utilized
                which are the server, defining a virtual server in itself that handles requests containing two
                directives: “listen” to set the IP address the server should respond to and “server_name”. The location
                is another context worth mentioningto be mentioned that further divides the request handling, this time
                by URL routes, in our case simply “/”. One level deeper into the block of code, the proxy_pass directive
                ensures passing the request to a proxied server, while the upstream context defines a pool of servers
                that can be used. Once each command has proven to successfully and independently spin up the containers
                linked to each other, naturally, we can tackle with Docker Compose, a tool for “running multi-container”
                applications. One of the most notable benefits of this technology is that other developers can easily
                contribute to the project, by simply running a command rather than manually configuring the whole
                environment needed. To set this up, the docker-compose.yml placed at the root of the project must be
                written. This file cumulates our efforts, by firstfirstly defining the version number which sets the
                format in which the code ought to be written in.
            </div>
            <div>
                MariaDB as a service utilizes container_name in order for the database configuration in the application
                to match the host and the image is pulled from the Docker Hub. We preserve data through persistent
                volumes managed by Docker. Moreover, the env_file sets the environment variables from a file as in this
                way, the file could potentially be excluded from the preferred version control protecting sensitive
                information. The command mysqld --init-file="/tmp/database/install_db.sql" creates the database and the
                tables, provided that they do not exist, populating them on the same reasoning.
            </div>
            <div>
                The NodeJS application as a service builds itself from the Dockerfile previously tested, “deploy”
                specifying its deployment as a running service with 3 replicas, handled by the load balancer, as well as
                a restart_policy for when the containers exit with 3 attempts to revive on failure. depends_on expresses
                the dependency between the application and the database and sets the dependency order, the services
                starting one by one, guided by it.
            </div>
            <div>
                The Nginx as a service, builds itself similarly, from the Dockerfile, sets its dependencies and exposes
                the port 80 for outside requests. The division of the services in networks is done through a bridge
                driver, providing out of the box DNS resolution, meaning if they do not belong to the same default
                network, they cannot access each other’s IP addresses. This in turn, contributes to security.
            </div>
        </div>

        <a id="SoftwareQA"></a>
        <div class="subheader1">Software Quality Assurance</div>
        <div>
            <a id="SoftwareQACodingStandard"></a>
            <div class="subheader2">Coding Standard</div>
            <div class="text">
                <div>
                    Coding standard is a collection of guidelines for programming style, techniques, and procedures for
                    each part of the program developed in a specific programming language that are agreed upon amongst
                    the developers. The standard commonly includes indentation, naming convention, comments, file
                    organization, and architectural best practices.
                </div>
                <div>
                    In a collaborative project, developers must establish a coding standard and conform with it to
                    improve code readability, consistency, reusability, and maintenance. By ensuring that the source
                    code is readable and understandable, other team members can easily get involved and contribute to
                    it. Moreover, the software is subject to security vulnerabilities if it is inconsistent, has bugs,
                    or has logical problems. These aforementioned issues are usually caused by defective programming
                    codes that may arise as a result of poor coding practices. Faulty codes also affect the site’s
                    performance negatively, in performance fields such as server response, code reusability, and user
                    interaction. Lastly, following the coding standard is cost effective. Clean and neat code helps
                    developers to find bugs and errors comparatively easily.
                </div>
                <div>
                    There are some tools that assists developers with the coding standard. For our project, we are using
                    a Visual Studio Code extension called ‘Prettier’. It is a code formatter that helps with rules such
                    as indentation and white space. As a group of developers with different coding background and
                    different development environment, we chose the ‘Prettier’ formatter to establish code format rules
                    and enforce consistent code style. It is also a useful tool as it is fully automated and updates
                    code format whenever the file is saved.
                </div>
                <div>
                    For the rest of the standards, we followed the general coding conventions for JavaScript programming
                    language. Some of the examples includes below:
                    <ul>
                        <li>Use ‘===’ instead of ‘==’ as a comparison operator: The former prevents comparisons between
                            different types.
                        </li>
                        <li>
                            Use ‘let’ or ‘const’ instead of ‘var’: For modifiable variables, use let – for anything
                            else, use ‘const’. This helps preventing scope issues.
                        </li>
                        <li>
                            Use semicolons (;): Even though it is optional in JavaScript, it is recommended to use
                            semicolons for code consistency and clearer statement separation. Use ES6 arrow functions:
                            Arrow functions are neater and more concise.
                        </li>
                        <li>
                            Naming convention: Use camel case for variable and function names.
                        </li>
                    </ul>
                </div>
                <div>
                    Lastly, for the file organization, we are following the Model-View-Controller pattern. Model
                    component is designated for the data structure, while View component is responsible for displaying
                    the data. Between the view and the model lies the Controller component. It listens for any events
                    triggered by the view component and responds appropriately. Because our project is minimal and
                    small, we do not have the model component. All the components related to views and controllers,
                    however, are put in the folder respectively.
                </div>
                <div>
                    An extra folder/directory we have in our project is called ‘routes’. This is responsible for
                    rerouting the application or calling responsible controllers depending on the different incoming
                    requests. + util, database…. etc?
                </div>
            </div>

            <a id="SoftwareQARelevancy"></a>
            <div class="subheader2">Relevancy of Tests</div>
            <div class="text">
                <div>
                    Code testing is highly relevant in any software deliverable because it enhances the developer’s
                    ability to track down bugs and simultaneously mitigate their occurrence. Moreover, testing heightens
                    one’s focus when writing code in regards to parameters, code functionality, possible errors etc,
                    which in turn builds better, more efficient code. When it comes to deployment, this becomes less
                    painful and last-minute bugs can easily be tracked down.
                </div>

                <div>
                    There are a myriad of testing types out of which we can highlight unit, integration, regression and
                    end-to-end testing, each with their own particularities. These can differ in scope, as in verifying
                    the code’s logic vs. the application’s behaviour in certain simulated circumstances, in scale, as in
                    units of code vs. the full flow of the project and in external interactions, as in HTTP calls or
                    services communications.
                </div>

                <div>
                    For the NodeJS project we have implemented both unit and integration testing through Mocha, Chai and
                    Docker. Mocha is a library used in conjunction with Chai, providing in this way the path for
                    creating test suites. The first distinguishes itself through providing keywords like “describe” and
                    “it” to describe the test’s scope and then define the block of code which is meant to be executed.
                    Tests are based on assertions which “encapsulate the logic specified about a target under test” and
                    by either failing or succeeding they dictate the test’s result.
                </div>

                <div>
                    Best practices which we have tried to include refer to describing the test at least two levels deep
                    with the purpose of explaining what is being tested, in which scenario and the expectations
                    regarding the result. Also, Docker was used for integration testing in order to avoid polluting the
                    production database and when the scope of the test was oriented towards code dependent on data but
                    not directly engaging with the database, substitute objects of data were provided directly in the
                    code files to speed up the process and protect the test’s integrity.

                </div>

                <div>
                    When it comes to the relevancy of the tests, we have to ask ourselves about the most important
                    chunks of code that keep our application alive while having in mind the requirements specification.
                    Related to business logic, the authentication is one of the crucial elements making up the
                    application. Both page flow and routing can be tested under the umbrella involving the information
                    exchange between the database layer and the presentation layer. Regarding this exchange, data flows
                    through methods in the models for the user and the event so these, alongside with targeted queries
                    could serve as a starting point for the integration testing. Lastly, what the user sees is sanitized
                    data so the utility methods should also have their fair share of attention in the testing workflow.
                </div>
            </div>

            <a id="SoftwareQATesting"></a>
            <div class="subheader2">Testing</div>
            <div class="text">
                <div>
                    To prepare the playground for testing, we have installed Mocha and Chai as development dependencies
                    alongside with ESLint, a technology that helps by identifying stylistic errors and hence, improving
                    code quality. In conjunction with these, InstanbulJS serves as a test code coverage measuring tool.
                </div>

                <div>
                    Execution involved taking in consideration the folder structure to ensure a clear separation of
                    concerns, hence the test and integration folders hold our files for testing and a secondary MariaDB
                    deployment through Docker. The package.json sets the configurations for InstanbulJS with code
                    coverage for branches and lines set to 30 respectively 50, which is currently not aligned with the
                    best practice that employs as a reasonable goal with 70-80% coverage as a minimum acceptance
                    criteriaacceptable.
                </div>
                <img src="././pages/images/testing1.png" alt="Testing package.json Settings" />

                <div>
                    The script for running the test involves the reporters “html” and “text” for outputting the results,
                    while checking the coverage is done through nyc by setting it to true, which yields the analysis’
                    result in the terminal.
                </div>
                <img src="././pages/images/testing2.png" alt="Testing package.json Scripts" />

                <div>
                    Diving deeper into the test files, business.spec.js handles the business logic with the chaiHttp
                    library added in order to harness the true potential of integration testing and make requests to the
                    application routes. The tests are targeting the GET method involving both ‘/dashboard’ and
                    ‘/profile’ routes with and without authentication. This is executed by setting the local storage
                    session ID with a user ID corresponding to an entry in the database. The POST method in
                    authentication verifies sign up, while the 404 error is ensured to be thrown with passing the
                    ‘/incorrect’ route and checking the result status.
                </div>

                <div>
                    ‘integration.spec.js’ includes the test database which replicates the data and targets core methods
                    involving user handling, such as fetching the user by email, by ID or creating a new user, email
                    handling, with fetching all of the events and database queries for retrieving the user by email and
                    the event by title. “expect” belongs to one of the assertion styles that Chai provides, alongside
                    with other flavours such as “should”. When speaking about the containerization, the Dockerfile pulls
                    the MariaDb image from the Docker Hub, setting the environment variables and running the
                    ‘init_db.sql’ file to populate it with data. Port 3308 is exposed in order to avoid clashing with
                    port 3306 used by the application. The initialization script creates the techevents_users.users and
                    techevents_users.events tables and INSERT IGNORE ensures that the process will not crash in the case
                    of data already inserted.
                </div>

                <div>
                    Lastly, ‘sanitization.spec.js’ tests the utility methods through already defined data objects for
                    the events and the user, focusing on the recommendation algorithm retrieval by assigning the user
                    object different professions which calculate through the formatSimilarity method the event count of
                    suitable suggestions. Moreover, the sanitization of the price for the presentation layer occurs
                    through test cases involving different data variants which can be contained by the attendance_price
                    property of the event.
                </div>
            </div>

            <a id="SoftwareQALinting"></a>
            <div class="subheader2">Linting</div>
            <div class="text">
                <div>
                    Linting is the process of testing your source code for syntactic and stylistic problems using an
                    automated system. A lint tool, also called a linter, performs static code analysis, meaning it
                    analyzes the source code without running the application. A linter can help enforce coding
                    standards. It also helps reduce cost because a linter may detect bugs and errors before deployment.
                </div>

                <div>
                    ESLint is one of several lint tools available for JavaScript. ESLint is a relatively new and widely
                    used tool for linting JavaScript code. It is built to be readily expandable and includes a number of
                    plugins. It's also noted for having the finest ES6 support and for being the only linter that works
                    with JSX. We opted to utilize ESLint as our linting tool for the project based on our research. We
                    utilize the ‘env: {“node”: true}’ option in the ‘.eslintrc.json' file to allow the linter to
                    recognize that the project is built using the node environment. Moreover, because Mocha and Chai
                    syntax are unrecognized by the linter and flags errors, we generated a file named ‘.eslintignore' to
                    exclude the ‘test' directory.
                </div>

                <div>
                    As a rule ESlint ensures that global variables are read-only, meaning that you shouldn’t change that
                    variable. This rule is called ‘no-global-assign’. We do however change the localStorage to save the
                    user id which of course threw errors. To fix this we changed the ‘.eslintrc.json’ file to state that
                    the global variable ‘localStorage’ should also be a ‘writable’:
                </div>

                <img src="././pages/images/linting1.png" alt="Linting Global Settings" />

                <div>
                    Another issue we came across were 4 presumably unused functions in our JavaScript code. This was
                    however not the case but the functions are called in the .html and .ejs files which ESlint doesn’t
                    check. We tried with several of their plugins but these were however only for recognizing html or
                    ejs syntax in other file types. To avoid omitting the whole folder ‘public’ and not linting the
                    JavaScript code in here, we added a line before each of the functions, telling the linter to disable
                    the check for ‘no-unused-vars’ on the next line:
                </div>

                <img src="././pages/images/linting2.png" alt="Linting Comment" />
            </div>

            <a id="SoftwareQACICD"></a>
            <div class="subheader2">CI/CD</div>
            <div class="text">
                <div>
                    The CI / CD pipeline involves a series of automated processes, for our specific case, testing,
                    coverage and linting, which are integrated with the version control. In this way, by frequently
                    committing, the integration allows for consistency and quality, ensuring through the tools
                    previously listed that the code is up to the standards.
                </div>

                <div>
                    To break these terms down for the sake of clarity, continuous integration implies that the
                    developers are constantly integrating their code with the main branch, enhancing collaborative work
                    and keeping away from time wasting activities that would result from excessive individual labour. In
                    this step, several safety pillars in the form of automated processes ensure the code’s quality.
                    Continuous delivery gets into play afterwards implying that the team has in place an automated way
                    of deploying and deliveringdelivery the systems in a dedicated infrastructure. Hence, due to its
                    highly collaborative nature and focus on software, rather than documentation CI/CD is in itself an
                    agile methodology.
                </div>

                <div>When it comes to implementation, there were many paths that initially seemed plausible however, in
                    the end, through trial and error there was only one viable solution left. Starting with
                    package.json, this hold the scripts to run in the .gitlab-ci.yml file for testing locally in its
                    full glory, coverage with partial testing and linting. One might wonder why testing is split. Given
                    that we are using two different databases for testing, the production one and a replica, we found
                    ourselves facing a difficult issue: how to run standalone databases in the pipeline’s environment?
                    Hence there were a few unsuccessful attempts which are as it follows:

                    <ul>
                        <li>Using a registry Dockerfile integrating the Docker Hub image of the full blown environment
                            created through docker-compose for the application. Issues arised:
                            <ul>
                                <li>port clashing between the npm test command and the application solved through
                                    pushing another Docker Hub image without CMD [“npm”, “start”] in the Dockerfile;
                                </li>
                                <li>
                                    exiting container later on prevented through ENTRYPOINT ["tail", "-f", "/dev/null"]
                                    added in the registry Dockerfile;
                                </li>
                                <li>
                                    database connection in closed state when running the tests.
                                </li>
                            </ul>
                        </li>
                        <li>Services in .gitlab-ci.yml file.</li>
                    </ul>
                </div>

                <img src="././pages/images/testing2.png" alt="CICD package.json Scripts" />

                <div>
                    Following these, we have restricted ourselves to running database independent tests through npm run
                    coverage. Locally, npm test outputs the tests with their failing or succeeding status, as well as
                    code coverage measuring for statements, branches, functions and lines in coverage.txt. The registry
                    Dockerfile now simply contains the application with Node installed in an Alpine based environment.
                    The ‘.gitlab-ci.yml’ file uses the registry image and caches the node_modules/ so that the project’s
                    dependencies do not have to be fetched multiple times. Stages are defined, of relevance to this
                    section: build which installs the aforementioned dependencies and test which runs the commands npm
                    run coverage and npm run lint, preventing on failure the pipeline from succeeding.
                </div>
            </div>

            <a id="SoftwareQAGitLabPages"></a>
            <div class="subheader2">GitLab Pages</div>
            <div class="text">
                <div>
                    When using GitLab, developers can generate static websites using GitLab pages. There are multiple
                    Static Site Generators (SSG) such as Jekyll, Hugo, and Hexo. Because our project is built with
                    NodeJSNode.js, however, there are a few difficulties in generating a static website out of our
                    project. Therefore, we decided to use the static GitLab pages as an introduction to our project as
                    well as our project report.
                </div>

                <img src="././pages/images/pages1.png" alt="GitLab Pages CI/CD File" />

                <div>
                    To utilize the GitLab Pages, we included a stage named ‘deploy’ in our ‘.gitlab-ci.yml’ file. The
                    YML file describes how a Runner should construct the static website. Using the customized registry
                    image, we are running three scripts in this stage: ‘mkdir .public’, ‘cp -r * .public’, and ‘mv
                    .public public’. When the pipeline is running, the Runner will create a directory named ‘.public’
                    within the container, copy all the files recursively into the ‘.public’ directory, and move that
                    directory to another folder called ‘public’. Then, we are providing a path to the ‘public’ directory
                    as a path to the artifacts of the website which will be uploaded to GitLab. Lastly, the ‘only’
                    directive specifies that the job will be running only when the codes are pushed into the ‘master’
                    branch.
                </div>
            </div>

            <a id="SoftwareQADocumentation"></a>
            <div class="subheader2">Documentation</div>
            <div class="text">
                <div>
                    A documentation in software development is written text or a graphic that describes the source
                    code. It explains how the program works or how to operate it. The purpose of the documentation is to
                    easily keep track of different modifications on different parts of an application so that developers
                    can maintain code and transfer knowledge fluently and seamlessly. A good documentation is where it
                    assists newcomers with learning the product, reduce support cost, and allow information to be easily
                    accessible. In our project, we created two types of documentations depending on its purpose: user
                    documentation and developer documentation.
                </div>

                <div>
                    User documentation is a manual primarily written for end-users and system administrators who uses
                    the product. It includes information such as installation, usage guide, and troubleshooting. In the
                    ‘README.md’ file, we are providing a step-by-step guide how to install, run, and test our project.
                    It also explains how to stop the application along with a link to our GitLab pages and screenshot
                    images of our web application.
                </div>

                <div>
                    For the developer documentation, we are using a markup language called JSDoc to generate the
                    documentation for our JavaScript-based project. As the below example shows, the documentations are
                    placed inside the comment that starts with ‘/**’ and ends with ‘*/’. The text within those comments
                    will be detected by the JSDoc parser and it will generate the documentation automatically. The tags,
                    such as ‘@constructor’ and ‘@param’ are used to include more specific information for components
                    such as functions and classes. Once the project is updated with comments, we ran ‘jsdoc {file_name}’
                    command to auto-generate HTML documentation files.
                </div>

                <img src="././pages/images/documentation1.png" alt="Documentation Example" />
            </div>
        </div>

        <a id="VersionControl"></a>
        <div class="subheader1">Version Control System</div>
        <div class="text">
            <div>
                Version control is the process of monitoring and handling modifications to software code. A version
                control system is a tool that aid software development teams in managing and tracking source code
                updates. For high-performing applications and DevOps departments, using version management software is a
                best practice. Version management also lets developers work more quickly and encourages development
                projects to maintain productivity and agility as the team grows.
            </div>

            <div>
                In our project, we implement the Git Feature Branch workflow. Theoretically, any developing features
                should be done on a dedicated branch instead of working directly on the master branch. This is to
                encapsulate and protect the code base and to ensure the main branch will never contain broken code.
                Moreover, it also forces developers to create a pull request each time they complete a feature and would
                like to merge it to the code base where other developers on the team can check, approve, and discuss the
                feature. However, because the web application code was completed before the project started, we have not
                created a separate feature branch for developing the web application.
            </div>

            <div>
                For the rest of the project development, including features such as dockerization and software quality
                assurance, we created a branch called ‘development’. As a standard, the members agreed upon creating a
                new branch every time a member works on a feature. Once the feature is completed, the member creates a
                pull request to the ‘development’ branch, not ‘master’ branch. In this way, we ensured that we share our
                work and only push approved working codes into the main branch.
            </div>
        </div>

        <a id="DatabaseSystem"></a>
        <div class="subheader1">Database System</div>
        <div class="text">
            <div>
                Choosing a database is one of the most crucial parts when developing a website. The database paradigm
                has to match the needs of the application. In our case we have a website where users can see events and
                add any events to their own schedule so they can have a clear overview of what they are participating
                in.
            </div>

            <div>
                Looking at our requirement specifications from a business point of view we want to be able to have many
                users who will all be saving and adding events to their own personal schedule. With this requirement it
                is important to have a database where it’s possible for several users to interact with the database at
                the same time. Another requirement for this website is that users should be able to browse events,
                comment and manage their schedules. This means a lot of data will be intertwined throughout the website.
                Since we will be having a lot of relational data it makes sense to pick a Relational Database Management
                System, RDBMS.
            </div>

            <div>
                There’s a lot of advantages when picking this type of database for our case. A relational database
                follows the ACID model which creates a very reliable system. ACID stands for Atomic, Consistent,
                Isolated and Durable[DB1]. When each of those properties come together it means that all transactions
                and actions on the website will happen only when all parts of the action are complete. Nothing will be
                sent to the database unless all required fields are filled out and the connection to the database is a
                success. If a crash happens to the server and the connection to the database is cutoff it will roll back
                and not save anything.
                Another important aspect of the ACID principle is that everything happens in isolation. Multiple users
                can perform updates to their own profile since each user is assigned a row in the database and will only
                manipulate that assigned row. So, if another user starts updating their profile, they will only be
                manipulating their own row and no one else’s. At the same time no user has to wait until another user is
                done to be able to edit their profile.
            </div>

            <div>
                Even though our database choice seemed very “cut and dry” there are still downsides by using a
                relational database. For larger companies that store an endless amount of data it might be a very
                expensive choice of database since it scales vertically, meaning it needs much more RAM and CPU-power to
                be able to store all the data. Another downside can be the very rigid schema. All tables should be
                normalized so you don’t have any empty cells, no repeated data and whenever you delete something it
                should cascade all the way through the website. This is where NoSQL databases come in. NoSQL means “not
                only SQL”. It’s not a paradigm but it’s a wider term covering database paradigms such as key/value,
                document or graph based databases. NoSQL databases have a much more relaxed schema for those who want to
                be more flexible with their data. Another advantage for NoSQL databases is that they scale horizontally
                which means you can have the database running on many servers and this is much cheaper compared to
                vertical scaling.
            </div>

            <div>
                Where the RDBMS are ACID compliant, NoSQL databases are BASE compliant. BASE stands for Basic
                Availability, Soft-state and Eventual Consistency. This all contributes to the very relaxed schema where
                the database isn’t necessarily consistent, but it is always available through at least one server.
            </div>

            <div>
                Many larger companies can benefit from using multiple database systems for individual tasks, but a sage
                choice is always to use a relational database since it provides the biggest safety net[DB2]. Because of
                the transactions in a relational database, you will never have any data stored that doesn’t belong and
                if something goes wrong, you’ll be sure it doesn’t go to the database.
            </div>

            <div>
                Taking the benefit of speed and horizontal scaling of NoSQL into consideration it doesn’t overshadow the
                advantages of the reliable schema and the ACID properties of a relational database and since we know
                exactly how we want to store our data and its relations a relational database is the best choice for us.
            </div>
        </div>

        <a id="OperatingSystem"></a>
        <div class="subheader1">Operating System Components</div>
        <div class="text">
            <div></div>

            <div></div>

            <div></div>
        </div>
    </div>
</body>

</html>